import gradio as gr
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Load pre-trained model
model_name = "j-hartmann/emotion-english-distilroberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
model.eval()

# Emotion labels from the model
labels = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']

# Emotion prediction function
def predict_emotion(text):
    if not text.strip():
        return {"Error": 1.0}
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
    scores = probs[0].tolist()
    return {labels[i]: round(scores[i], 3) for i in range(len(labels))}

# Gradio interface
demo = gr.Interface(
    fn=predict_emotion,
    inputs=gr.Textbox(lines=4, placeholder="Enter a social media message here..."),
    outputs=gr.Label(num_top_classes=3),
    title="ðŸ§  Emotion Detection in Social Media",
    description="This app predicts the emotion expressed in a text (anger, joy, sadness, etc.) using a fine-tuned transformer model."
)

# Launch app
if __name__ == "__main__":
    demo.launch()
